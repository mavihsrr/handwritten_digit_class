{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43e5303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb100be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4e0d955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b2ee6f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24ecb1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b784c94490>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#showing\n",
    "plt.matshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "da669c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c8f55430",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_flatten =  x_train.reshape(len(x_train),28*28)/255\n",
    "x_test_flatten =  x_test.reshape(len(x_test),28*28)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ffc0d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "       0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "       0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.11764706, 0.14117647, 0.36862745, 0.60392157,\n",
       "       0.66666667, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.88235294, 0.6745098 , 0.99215686, 0.94901961,\n",
       "       0.76470588, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.19215686, 0.93333333,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.98431373, 0.36470588,\n",
       "       0.32156863, 0.32156863, 0.21960784, 0.15294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.85882353, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.71372549,\n",
       "       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31372549, 0.61176471, 0.41960784, 0.99215686, 0.99215686,\n",
       "       0.80392157, 0.04313725, 0.        , 0.16862745, 0.60392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "       0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54509804,\n",
       "       0.99215686, 0.74509804, 0.00784314, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.04313725, 0.74509804, 0.99215686,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.1372549 , 0.94509804, 0.88235294, 0.62745098,\n",
       "       0.42352941, 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.31764706, 0.94117647, 0.99215686, 0.99215686, 0.46666667,\n",
       "       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "       0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.0627451 , 0.36470588,\n",
       "       0.98823529, 0.99215686, 0.73333333, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.97647059, 0.99215686,\n",
       "       0.97647059, 0.25098039, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18039216, 0.50980392,\n",
       "       0.71764706, 0.99215686, 0.99215686, 0.81176471, 0.00784314,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15294118,\n",
       "       0.58039216, 0.89803922, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.98039216, 0.71372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09019608, 0.25882353, 0.83529412, 0.99215686,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.77647059, 0.31764706,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.67058824, 0.85882353,\n",
       "       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.76470588,\n",
       "       0.31372549, 0.03529412, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.21568627, 0.6745098 ,\n",
       "       0.88627451, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.95686275, 0.52156863, 0.04313725, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.53333333, 0.99215686, 0.99215686, 0.99215686,\n",
       "       0.83137255, 0.52941176, 0.51764706, 0.0627451 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_flatten[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d9777ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4629 - accuracy: 0.8799\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3035 - accuracy: 0.9154\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2831 - accuracy: 0.9208\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2728 - accuracy: 0.9239\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2661 - accuracy: 0.9260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b7f28ecdf0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a simple NN with only 2 layers i/o\n",
    "model = keras.Sequential([ keras.layers.Dense(10, input_shape=(784,),activation='sigmoid' )\n",
    "                 ])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_flatten,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4350bb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.2698 - accuracy: 0.9250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26980650424957275, 0.925000011920929]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_flatten,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cbe6123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b7a01a7460>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAECCAYAAAD+eGJTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOGElEQVR4nO3df6xf9V3H8ddr7e1lvS2uHaPWUqhjbJHNUcwdbAFNF2SyLaSQbbgmNjWZK1FIwCwqIVlook4k/BCdkhSp6xZgwxWEbHWuaaZIxI7SFFpaFMSirZdeoNOWAf359o97ild27+d7e7/f7znf2/fzkTTf7/e8z/ecd09vX/dzzvdzz3VECEBe72i6AQDNIgSA5AgBIDlCAEiOEACSIwSA5BoJAduX2f4X28/bvqGJHkps77K9zfZW25t7oJ81todtbx+1bK7tDbafqx7n9Fh/q2zvqY7hVtufarC/hbZ/YHuH7WdsX1ct74ljWOivlmPouucJ2J4m6V8lXSppt6QnJC2LiB21NlJge5ekwYh4peleJMn2L0l6TdLXI+JD1bJbJO2LiJurIJ0TEb/XQ/2tkvRaRNzaRE+j2Z4vaX5EbLE9W9KTkq6Q9OvqgWNY6O8q1XAMmxgJXCDp+Yh4ISIOSfqmpKUN9DFlRMSjkva9bfFSSWur52s18kXTiHH66xkRMRQRW6rnByTtlLRAPXIMC/3VookQWCDpP0e93q0a/8ITFJK+b/tJ2yubbmYc8yJiqHr+kqR5TTYzjmttP12dLjR2ujKa7UWSzpe0ST14DN/Wn1TDMeTC4NgujohfkPRJSddUw92eFSPndL02//suSWdLWixpSNJtjXYjyfYsSeskXR8R+0fXeuEYjtFfLcewiRDYI2nhqNdnVMt6RkTsqR6HJT2kkVOYXrO3Opc8fk453HA//09E7I2IoxFxTNLdavgY2u7TyH+weyPiwWpxzxzDsfqr6xg2EQJPSDrH9s/aniHp85IeaaCPMdkeqC7OyPaApE9I2l5+VyMekbSier5C0sMN9vITjv/nqlypBo+hbUu6R9LOiLh9VKknjuF4/dV1DGv/dECSqo86/kTSNElrIuIPa29iHLbfq5Hv/pI0XdJ9Tfdn+35JSySdJmmvpJsk/Y2kBySdKelFSVdFRCMX58bpb4lGhrEhaZekq0edf9fd38WS/lHSNknHqsU3auS8u/FjWOhvmWo4ho2EAIDewYVBIDlCAEiOEACSIwSA5AgBILlGQ6CHp+RKor929XJ/vdybVG9/TY8EevofQvTXrl7ur5d7k2rsr+kQANCwtiYL2b5M0p0amfn3lxFxc2n9Ge6PUzTw1uvDOqg+9U96/91Gf+3p5f56uTep8/29qR/rUBz0WLVJh8Bkbg5yqufGhb5kUvsDMHmbYqP2x74xQ6Cd0wFuDgKcBNoJgalwcxAALUzv9g6qjzpWStIpmtnt3QE4Qe2MBCZ0c5CIWB0RgxEx2MsXYoCs2gmBnr45CICJmfTpQEQcsX2tpL/T/90c5JmOdQagFm1dE4iI9ZLWd6gXAA1gxiCQHCEAJEcIAMkRAkByhACQHCEAJEcIAMkRAkByhACQHCEAJEcIAMkRAkByhACQHCEAJEcIAMkRAkByhACQHCEAJEcIAMkRAkByhACQHCEAJEcIAMkRAkByhACQHCEAJEcIAMkRAkByhACQHCEAJEcIAMlNb+fNtndJOiDpqKQjETHYiaYA1KetEKh8PCJe6cB2ADSA0wEguXZDICR93/aTtld2oiEA9Wr3dODiiNhj+3RJG2w/GxGPjl6hCoeVknSKZra5OwCd1tZIICL2VI/Dkh6SdMEY66yOiMGIGOxTfzu7A9AFkw4B2wO2Zx9/LukTkrZ3qjEA9WjndGCepIdsH9/OfRHxvY50BaA2kw6BiHhB0nkd7AVAA/iIEEiOEACSIwSA5AgBIDlCAEiOEACS68RPEabx6hc/Vqyfufz5Yv3Z4XnF+qGDfcX6gvvL9Zm7XyvWj23dUawjJ0YCQHKEAJAcIQAkRwgAyRECQHKEAJAcIQAkxzyBE/C7v3Nfsf6ZgR+VN3B2mw0sKZd3HXm9WL/z5Y+32cDU9sPhs4r1gdt+qlifvvHJTrbTMxgJAMkRAkByhACQHCEAJEcIAMkRAkByhACQnCOitp2d6rlxoS+pbX+d9uPPXlisv/LhcqbO2Vk+1j/6ORfrMz7838X6LR96sFi/9J1vFOvffX1Wsf7pmeX7FbTrjThUrG86OFCsLznlcFv7f993ry7W37/yiba236RNsVH7Y9+YX2CMBIDkCAEgOUIASI4QAJIjBIDkCAEgOUIASI77CZyAgW9valFvb/untvd2/dlPLynW/+CiReX9/0P59ybcsuR9J9jRiZn+xrFifeDpoWL93Y+uK9Z/fkaL39uwq1w/WbUcCdheY3vY9vZRy+ba3mD7uepxTnfbBNAtEzkd+Jqky9627AZJGyPiHEkbq9cApqCWIRARj0ra97bFSyWtrZ6vlXRFZ9sCUJfJXhicFxHHT9BeklT+JXsAelbbnw7EyE8gjfuTMbZX2t5se/NhHWx3dwA6bLIhsNf2fEmqHofHWzEiVkfEYEQM9ql/krsD0C2TDYFHJK2onq+Q9HBn2gFQt5bzBGzfr5E73p9me7ekmyTdLOkB21+Q9KKkq7rZJCbmyEt7i/WBdeX60RbbH/j2qyfYUWft/Y2PFesfnFH+cr513weK9UV/9UKxfqRYnbpahkBELBunNHXvDgLgLUwbBpIjBIDkCAEgOUIASI4QAJIjBIDkuJ8Aesb0sxYW61+98avFep+nFet/fecvF+vvHnq8WD9ZMRIAkiMEgOQIASA5QgBIjhAAkiMEgOQIASA55gmgZzz72wuK9Y/0u1h/5tAbxfrcHa+fcE8ZMBIAkiMEgOQIASA5QgBIjhAAkiMEgOQIASA55gmgNgc//ZFifctn72ixhfJvsPrN664r1t/5Tz9ssf2cGAkAyRECQHKEAJAcIQAkRwgAyRECQHKEAJAc8wRQm//4ZPl7ziyX5wEs+/dLi/WZ33uqWI9iNa+WIwHba2wP294+atkq23tsb63+fKq7bQLolomcDnxN0mVjLL8jIhZXf9Z3ti0AdWkZAhHxqKR9NfQCoAHtXBi81vbT1enCnI51BKBWkw2BuySdLWmxpCFJt423ou2Vtjfb3nxYBye5OwDdMqkQiIi9EXE0Io5JulvSBYV1V0fEYEQM9rX4KTAA9ZtUCNieP+rllZK2j7cugN7Wcp6A7fslLZF0mu3dkm6StMT2Yo189LpL0tXdaxFTxTtmzy7Wl//iY8X6/mNvFuvDX3lvsd5/8IliHWNrGQIRsWyMxfd0oRcADWDaMJAcIQAkRwgAyRECQHKEAJAcIQAkx/0E0DHPrfpgsf6d0/6iWF/63GeK9f71zAPoBkYCQHKEAJAcIQAkRwgAyRECQHKEAJAcIQAkxzwBTNj//NpHi/Wnf/VPi/V/O3K4WH/tj88o1vs1VKxjchgJAMkRAkByhACQHCEAJEcIAMkRAkByhACQHPME8JbpC36mWL/+y98q1vtd/nL6/FPLi/X3/C33C2gCIwEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJJjnkAinl7+5z7vO7uL9c/NerVYv/fA6cX6vC+Xv+ccK1bRLS1HArYX2v6B7R22n7F9XbV8ru0Ntp+rHud0v10AnTaR04Ejkr4UEedK+qika2yfK+kGSRsj4hxJG6vXAKaYliEQEUMRsaV6fkDSTkkLJC2VtLZaba2kK7rUI4AuOqELg7YXSTpf0iZJ8yLi+E3fXpI0r7OtAajDhEPA9ixJ6yRdHxH7R9ciIiTFOO9baXuz7c2HdbCtZgF03oRCwHafRgLg3oh4sFq81/b8qj5f0vBY742I1RExGBGDfervRM8AOmginw5Y0j2SdkbE7aNKj0haUT1fIenhzrcHoNsmMk/gIknLJW2zvbVadqOkmyU9YPsLkl6UdFVXOkTnnPeBYvn3T/9GW5v/8698rlh/11OPt7V9dEfLEIiIxyR5nPIlnW0HQN2YNgwkRwgAyRECQHKEAJAcIQAkRwgAyXE/gZPItHPfX6yv/GZ787nOXXNNsb7oG//c1vbRDEYCQHKEAJAcIQAkRwgAyRECQHKEAJAcIQAkxzyBk8izv1W+6/vlM/cX662c8feHyivEmHeYQ49jJAAkRwgAyRECQHKEAJAcIQAkRwgAyRECQHLME5hC3rz8gmJ94+W3tdjCzM41g5MGIwEgOUIASI4QAJIjBIDkCAEgOUIASI4QAJJrOU/A9kJJX5c0T1JIWh0Rd9peJemLkl6uVr0xItZ3q1FI/3XRtGL9zOntzQO498DpxXrf/vL9BLibwNQ0kclCRyR9KSK22J4t6UnbG6raHRFxa/faA9BtLUMgIoYkDVXPD9jeKWlBtxsDUI8TuiZge5Gk8yVtqhZda/tp22tsl+9tBaAnTTgEbM+StE7S9RGxX9Jdks6WtFgjI4UxJ67bXml7s+3Nh3Ww/Y4BdNSEQsB2n0YC4N6IeFCSImJvRByNiGOS7pY05k+3RMTqiBiMiME+9XeqbwAd0jIEbFvSPZJ2RsTto5bPH7XalZK2d749AN02kU8HLpK0XNI221urZTdKWmZ7sUY+Gdol6eou9Aegyyby6cBjkjxGiTkBU8wfvXpusf74rywq1mNoWwe7Qa9gxiCQHCEAJEcIAMkRAkByhACQHCEAJEcIAMk5avyd8qd6blzoS2rbH4ARm2Kj9se+seb7MBIAsiMEgOQIASA5QgBIjhAAkiMEgOQIASC5WucJ2H5Z0oujFp0m6ZXaGjhx9NeeXu6vl3uTOt/fWRHxnrEKtYbAT+zc3hwRg4010AL9taeX++vl3qR6++N0AEiOEACSazoEVje8/1borz293F8v9ybV2F+j1wQANK/pkQCAhhECQHKEAJAcIQAkRwgAyf0vId/VeOm0tZcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(x_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a08c31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.83857919e-02, 2.76665304e-07, 4.75294068e-02, 9.54721808e-01,\n",
       "       2.31364858e-03, 9.04625431e-02, 1.64191783e-06, 9.99775350e-01,\n",
       "       1.07637145e-01, 6.57148421e-01], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_flatten)\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7e6cae57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71c1a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lab = [np.argmax(i) for i in y_pred]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "36590c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 966    0    2    2    0    3    4    1    2    0]\n",
      " [   0 1109    3    2    0    1    4    2   14    0]\n",
      " [   7    8  929   15    7    2   11    9   41    3]\n",
      " [   4    0   21  926    1   14    2    8   26    8]\n",
      " [   2    1    6    1  913    0    9    3   10   37]\n",
      " [  11    2    5   43   11  749   14    7   42    8]\n",
      " [  15    3    9    1    8   10  907    1    4    0]\n",
      " [   2    5   22    8    8    1    0  940    4   38]\n",
      " [   8    7    6   18    9   17    7    9  886    7]\n",
      " [  11    7    1   10   27    4    0   15    9  925]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "cm = confusion_matrix(y_test,y_pred_lab)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec34c5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2711 - accuracy: 0.9224\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1239 - accuracy: 0.9625\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0844 - accuracy: 0.9752\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0666 - accuracy: 0.9795\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0528 - accuracy: 0.9838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b7a0649f90>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding a hidden layer\n",
    "model = keras.Sequential([ keras.layers.Dense(100,input_shape=(784,),\n",
    "                        activation='relu' ),\n",
    "                    keras.layers.Dense(10,activation='sigmoid')\n",
    "                         ])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_flatten,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7444e2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1583/1875 [========================>.....] - ETA: 0s - loss: 2.6973 - accuracy: 0.8272"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m      2\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m,\u001b[38;5;241m28\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m100\u001b[39m,input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m784\u001b[39m,),\n\u001b[0;32m      4\u001b[0m         activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m ),\n\u001b[0;32m      5\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m10\u001b[39m,activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m                          ])\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m              metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1656\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1654\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[0;32m   1655\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[1;32m-> 1656\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:476\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \n\u001b[0;32m    471\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;124;03m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[1;32m--> 476\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModeKeys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:323\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m hook \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 323\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_end_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized hook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected values are [\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    328\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:346\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    343\u001b[0m     batch_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_start_time\n\u001b[0;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times\u001b[38;5;241m.\u001b[39mappend(batch_time)\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_batch_hook_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_times) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_batches_for_timing_check:\n\u001b[0;32m    349\u001b[0m     end_hook_name \u001b[38;5;241m=\u001b[39m hook_name\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:394\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m    393\u001b[0m     hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m--> 394\u001b[0m     \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timing:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hook_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hook_times:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:1094\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_train_batch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, logs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m-> 1094\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_update_progbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\callbacks.py:1170\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m add_seen\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;66;03m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[1;32m-> 1170\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[43mtf_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msync_to_numpy_or_python_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseen, \u001b[38;5;28mlist\u001b[39m(logs\u001b[38;5;241m.\u001b[39mitems()), finalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\tf_utils.py:665\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(t) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m--> 665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_single_numpy_or_python_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:917\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    913\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m    914\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> 917\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m    918\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\tf_utils.py:658\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;66;03m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, tf\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 658\u001b[0m         t \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;66;03m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;66;03m# as-is.\u001b[39;00m\n\u001b[0;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mgeneric)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1155\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;124;03m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m \n\u001b[0;32m   1134\u001b[0m \u001b[38;5;124;03mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[38;5;124;03m    NumPy dtype.\u001b[39;00m\n\u001b[0;32m   1153\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;66;03m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[1;32m-> 1155\u001b[0m maybe_arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m maybe_arr\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_arr, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m maybe_arr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1121\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_numpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1120\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_numpy_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(100,input_shape=(784,),\n",
    "        activation='relu' ),\n",
    "    keras.layers.Dense(10,activation='sigmoid')\n",
    "                         ])\n",
    "\n",
    "model.compile(optimizer = 'adam', loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857dbf25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
